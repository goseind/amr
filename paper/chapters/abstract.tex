\begin{abstract}
Autonomous robots already have a broad spectrum of practical applications like autonomous delivery vehicles, warehouse, or service robots. The technology has also found its way into cars and is used for autonomous driving. As the technology behind it becomes more applicable, the question is what can a minimal autonomous robot setup look like and how does it work? This paper aims to answer that question by building a prototype capable of navigating toward objects with just one front camera, using the Robot Operating System (ROS) to control the robot and You Only Look Once (YOLO) for object detection. The paper describes different approaches to navigation and object detection and their challenges. It also goes into performance differences between YOLOv4 and YOLOv5. The outcome shows that it is possible to build such a minimal setup and that the best combination is a remote computer, which runs the object detection and sends commands to the robot for navigation. It also shows that YOLOv5 is much faster and more precise than YOLOv4. The biggest challenge however remains with the computing and network performance. Even though YOLO is very resource-saving and fast, the results indicate that more computing power and network throughput would lead to more fluid navigation. The robot is a semester project conducted as part of the course Autonomous Mobile Robots at the University of Applied Sciences Mannheim.

\noindent
\textit{Keywords: yolo, yolov4, yolov5, robot, autonomous robot, ros, turtlebot, turtlebot3 burger, object detection}
\end{abstract}